{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer,Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Load weights\n",
    "inception = InceptionV3(weights='imagenet', include_top=True)\n",
    "inception.graph = tf.get_default_graph()\n",
    "\n",
    "print(\"finished loading inceptionv3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "\n",
    "def load_image_directory(path):\n",
    "    images = []\n",
    "    \n",
    "    images_name = os.listdir(path)\n",
    "    images_name.sort()\n",
    "    \n",
    "    for filename in images_name:\n",
    "        images.append(img_to_array(load_img('{0}{1}'.format(path, filename))))\n",
    "    images = np.array(images, dtype=float)\n",
    "    \n",
    "    return images\n",
    "\n",
    "test_images =  load_image_directory('./TrainFlowers/')[:50]\n",
    "colored_images = load_image_directory('./TrainFlowers/')[50:]\n",
    "\n",
    "Xtrain = 1.0/255 * colored_images\n",
    "x = 1.0/255 * colored_images\n",
    "y = 1.0/255* colored_images\n",
    "\n",
    "imgs = 1.0/255 * test_images\n",
    "imgs_to_predict =  rgb2lab(imgs)[:,:,:,0]\n",
    "imgs_to_predict = imgs_to_predict.reshape(imgs_to_predict.shape+(1,))\n",
    "\n",
    "#Load weights\n",
    "inception = InceptionV3(weights='imagenet', include_top=True)\n",
    "inception.graph = tf.get_default_graph()\n",
    "\n",
    "x = rgb2lab(x)[:,:,:,0]\n",
    "y = (rgb2lab(y)[:,:,:,1:]) / 128\n",
    "\n",
    "x = x.reshape(x.shape+(1,))\n",
    "#y = y.reshape(y.shape+(2,))\n",
    "print(\"finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_input = Input(shape=(1000,))\n",
    "\n",
    "#input here is 96x96 image, in our case the image after the super resolution\n",
    "encoder_input = Input(shape=(96, 96, 1,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "#input here is InceptionV3 final layer\n",
    "fusion_output = RepeatVector(12 * 12)(embed_input) \n",
    "fusion_output = Reshape(([12, 12, 1000]))(fusion_output)\n",
    "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
    "\n",
    "#input here are the encoder_output and fusion_output\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.00005, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "print(model.summary())\n",
    "print(\"created model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 100\n",
    "\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        embed = create_inception_embedding(grayscaled_rgb)\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n",
    "\n",
    "\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        plt.pause(0.05)\n",
    "        \n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "filepath = 'colorize-inv3-ep{epoch:03d}-loss{loss:.3f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')       \n",
    "# Train model      \n",
    "print(\"starting\")\n",
    "\n",
    "model.fit_generator(image_a_b_gen(batch_size), epochs=100, steps_per_epoch=80,\n",
    "                   callbacks=[plot_losses,checkpoint])\n",
    "\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "model = load_model('./colorize-inv3-ep083-loss0.017.h5')\n",
    "gray_me = gray2rgb(rgb2gray(1.0/255*test_images))\n",
    "color_me_embed = create_inception_embedding(gray_me)\n",
    "color_me = rgb2lab(1.0/255*test_images)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = model.predict([color_me, color_me_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((96, 96, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"results/clr3_img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "model = load_model('./colorize-inv3-ep083-loss0.017.h5')\n",
    "color_me = []\n",
    "\n",
    "grey_images = load_image_directory('./BWFlowers/')[:50]\n",
    "color_me = np.array(grey_images, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(5):\n",
    "    cur = np.zeros((96, 96, 3))\n",
    "    cur[:,:,0] = np.reshape(color_me[i])\n",
    "    cur[:,:,1:] = output[i]\n",
    "    print(output[i].shape)\n",
    "    plt.imshow(lab2rgb(cur))\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
