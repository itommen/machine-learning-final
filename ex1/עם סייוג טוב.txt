import tensorflow as tf
import os
import tensorflow.examples.tutorials.mnist.input_data as input_data
import numpy as np
import matplotlib.pyplot as plt

def getImageDataToTest():
    BASE_PATH = "C:\\Users\\iTomM\\Desktop\\repositories\\machine-learning-final\\ex1\\images";
    current_folder_filename_list = os.listdir(BASE_PATH)
    image_data = tf.gfile.FastGFile(BASE_PATH + "\\" + current_folder_filename_list[0], 'rb').read()
    return tf.image.decode_jpeg(image_data)
    

def printMnistInfo(mnist):
    %matplotlib inline
    # mnist is now a DataSet with accessors for:
    #'train', 'test', and 'validation'.
    # within each, we can access:
    # images, labels, and num_examples
    print('train: ', mnist.train.num_examples)
    print('test: ', mnist.test.num_examples)
    print('validation: ', mnist.validation.num_examples)
    
    # print the images pixcels size
    print('images: (images, pixels)', mnist.train.images[1:2].shape)
    #print how much images, hot hot much classifications
    print('labels: (images, classifcations)', mnist.train.labels.shape)
    
    # print the images pixels range (0.0 - 1.0)
    print(np.min(mnist.train.images), np.max(mnist.train.images))
    
def printRandomImageFromMnistSet():
    plt.subplot(111)
    # we can visualize any one of the images by reshaping it to a 28x28 image
    plt.imshow(np.reshape(mnist.train.images[1:2], (28, 28)), cmap='gray')
    plt.show()

def printAccuricyGraph(l_loss):
    plt.subplot(222)
    plt.title('Logistic Regression Acuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epochs')
    plt.plot(l_loss, color='m')
    plt.show()
    print('l_loss:',l_loss)

def getModel():
    n_input = 784
    n_hidden = 256
    n_output = 10
    net_input = tf.placeholder(tf.float32, [None, n_input])
    #net_hidden = tf.placeholder(tf.float32, [None, n_hidden])

    W1 = tf.Variable(tf.truncated_normal ([n_input, n_hidden]))
    W2 = tf.Variable(tf.truncated_normal ([n_hidden, n_output]))
    b1 = tf.Variable(tf.truncated_normal([n_hidden]))
    b2 = tf.Variable(tf.truncated_normal ([n_output]))

    relu = tf.nn.relu(tf.matmul(net_input, W1) + b1)    
    return net_input, tf.nn.softmax(tf.matmul(relu, W2) + b2) # <-- THIS IS OUR MODEL!
    
def trainMachine(sees, l_loss):
    eta = 0.1
    optimizer = tf.train.GradientDescentOptimizer(eta).minimize(cost)
    
    batch_size = 5
    n_epochs = 5
    
    for epoch_i in range(n_epochs):
        for batch_i in range(0, mnist.train.num_examples, batch_size):        
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)        
            sess.run(optimizer, feed_dict={
                net_input: batch_xs,
                y_true: batch_ys
            })

        loss = sess.run(accuracy, feed_dict={
                           net_input: mnist.validation.images,
                           y_true: mnist.validation.labels })

        print('Validation accuracy for epoch {} is: {}'.format(epoch_i + 1, loss))
        l_loss.append(loss)
        
def testMachine(sess):
    print("Accuracy for test set: {}".format(sess.run(accuracy,
               feed_dict={
                   net_input: mnist.test.images,
                   y_true: mnist.test.labels
               })))

def testGivenImage(sess):
    # TODO: should check why are we using the mnist arg and not our image
    print("From File: ", sess.run(tf.argmax(net_output, 1),
               feed_dict={
                   net_input:  mnist.train.images[1:2]
               }))
    
image_to_test = getImageDataToTest()

# read the data and labels as ont-hot vectors
# one-hot means a sparse vector for every observation where only
# the class label is 1, and every other class is 0.
mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)

printMnistInfo(mnist)

printRandomImageFromMnistSet()

net_input, net_output = getModel()

y_true = tf.placeholder(tf.float32, [None, 10])

# prediction and actual using the argmax as the predicted label
correct_prediction = tf.equal(tf.argmax(net_output, 1), tf.argmax(y_true, 1))

# And now we can look at the mean of our network's correct guesses
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

# TODO: SHOULD CHECK WHY WE NEVER USE THIS ARG
cross_entropy = -tf.reduce_sum(y_true * tf.log(net_output))

sess = tf.Session()
sess.run(tf.global_variables_initializer())

cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=net_output, labels=y_true))

l_loss = list()

trainMachine(sess, l_loss)

printAccuricyGraph(l_loss)

testMachine(sess)

testGivenImage(sess)